{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25e4a6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fbb41bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn module, base class (parent) for all model/layer in pytorch\n",
    "# nn.Module handle parameters(weight and bias), autosave in parameters() -> use for train\n",
    "# define Forward rule, just write def forward -> pytorch handle backpropagation(gradient)\n",
    "# sp composition, build layer from other layers (LEGO)\n",
    "# multiple utils like, .train(), .eval(), .cuda(), .cpu(), .state_dict() -> save/load model\n",
    "class Conv(nn.Module):\n",
    "    def __init__(self, c_in, c_out, k=1, s=1, p=None, g=1):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(c_in, c_out, k, s, autopad(k, p), groups=g, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(c_out)\n",
    "        self.act = nn.SiLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.act(self.bn(self.conv(x)))\n",
    "    \n",
    "def autopad(k, p=None):\n",
    "    if p is None:\n",
    "        # padding = kernel_size // 2\n",
    "        p = k // 2\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c980bb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    def __init__(self, c_in, c_out, shortcut=True):\n",
    "        super().__init__()\n",
    "        # c_in, nums of channel of input feature map (RGB -> c_in=3)\n",
    "        self.cv1 = Conv(c_in, c_out, 1, 1) # 1x1 conv\n",
    "        self.cv2 = Conv(c_in, c_out, 3, 1)\n",
    "        # skip connection if c_in = c_out, same the shape, channels\n",
    "        self.add = shortcut and c_in == c_out\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y = self.cv2(self.cv1(x))\n",
    "        return x + y if self.add else y # x + F(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb7bb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Cross Stage Partial\n",
    "# 2f = 2 fusion (merge 2 branch in bottleneck), cv1, cv2\n",
    "class C2f(nn.Module):\n",
    "    def __init__(self, c_in, c_out, n=1):\n",
    "        super().__init__()\n",
    "        hidden = c_out // 2\n",
    "        self.cv1 = Conv(c_in, hidden, 1, 1)\n",
    "        self.cv2 = Conv(c_in, hidden, 1, 1)\n",
    "        self.m = nn.Sequential(*[Bottleneck(hidden, hidden) for _ in range(n)])\n",
    "        self.cv3 = Conv(2 * hidden, c_out, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y1 = self.cv1(x)\n",
    "        y2 = self.m(self.cv2(x))\n",
    "        return self.cv3(torch.cat((y1, y2), 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "189cd986",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SPPF(nn.Module):\n",
    "    def __init__(self, c_in, c_out, k=5):\n",
    "        super().__init__()\n",
    "        hidden = c_in // 2\n",
    "        self.cv1 = Conv(c_in, hidden, 1, 1)\n",
    "        self.cv2 = Conv(hidden * 4, c_out, 1, 1)\n",
    "        self.m = nn.MaxPool2d(kernel_size=k, stride=1, padding=k // 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cv1(x)\n",
    "        y1 = self.m(x)\n",
    "        y2 = self.m(y1)\n",
    "        y3 = self.m(y2)\n",
    "        return self.cv2(torch.cat([x, y1, y2, y3], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7635942",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLOv8(nn.Module):\n",
    "    def __init__(self, num_classes=9):\n",
    "        super().__init__()\n",
    "        # Backbone\n",
    "        self.layer1 = Conv(3, 32, 3, 2)\n",
    "        self.layer2 = C2f(32, 64, n=1)\n",
    "        self.layer3 = Conv(64, 128, 3, 2)\n",
    "        self.layer4 = C2f(128, 128, n=2)\n",
    "        self.layer5 = Conv(128, 256, 3, 2)\n",
    "        self.layer6 = C2f(256, 256, n=2)\n",
    "        self.layer7 = Conv(256, 512, 3, 2)\n",
    "        self.layer8 = C2f(512, 512, n=1)\n",
    "        self.layer9 = SPPF(512, 512)\n",
    "\n",
    "        # Neck (FPN + PAN)\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode=\"nearest\")\n",
    "        self.c2f1 = C2f(512 + 256, 256, n=1)\n",
    "        self.c2f2 = C2f(256 + 128, 128, n=1)\n",
    "        self.down1 = Conv(128, 256, 3, 2)\n",
    "        self.c2f3 = C2f(256 + 256, 256, n=1)\n",
    "        self.down2 = Conv(256, 512, 3, 2)\n",
    "        self.c2f4 = C2f(512 + 512, 512, n=1)\n",
    "\n",
    "        # Head (3 scales)\n",
    "        self.detect_p3 = nn.Conv2d(128, 4 + 1 + num_classes, 1)\n",
    "        self.detect_p4 = nn.Conv2d(256, 4 + 1 + num_classes, 1)\n",
    "        self.detect_p5 = nn.Conv2d(512, 4 + 1 + num_classes, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Backbone\n",
    "        x1 = self.layer1(x)\n",
    "        x2 = self.layer2(x1)\n",
    "        x3 = self.layer3(x2)\n",
    "        x4 = self.layer4(x3)\n",
    "        x5 = self.layer5(x4)\n",
    "        x6 = self.layer6(x5)\n",
    "        x7 = self.layer7(x6)\n",
    "        x8 = self.layer8(x7)\n",
    "        x9 = self.layer9(x8)  # P5\n",
    "\n",
    "        # FPN\n",
    "        p5 = x9\n",
    "        p4 = self.c2f1(torch.cat([self.upsample(p5), x6], 1))\n",
    "        p3 = self.c2f2(torch.cat([self.upsample(p4), x4], 1))\n",
    "\n",
    "        # PAN\n",
    "        n4 = self.c2f3(torch.cat([self.down1(p3), p4], 1))\n",
    "        n5 = self.c2f4(torch.cat([self.down2(n4), p5], 1))\n",
    "\n",
    "        # Head\n",
    "        out_p3 = self.detect_p3(p3)\n",
    "        out_p4 = self.detect_p4(n4)\n",
    "        out_p5 = self.detect_p5(n5)\n",
    "\n",
    "        return [out_p3, out_p4, out_p5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "098e704e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "C2f.__init__() got an unexpected keyword argument 'n'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     model = \u001b[43mYOLOv8\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m9\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m     dummy = torch.randn(\u001b[32m1\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m640\u001b[39m, \u001b[32m640\u001b[39m) \n\u001b[32m      4\u001b[39m     outputs = model(dummy)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mYOLOv8.__init__\u001b[39m\u001b[34m(self, num_classes)\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Backbone\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mself\u001b[39m.layer1 = Conv(\u001b[32m3\u001b[39m, \u001b[32m32\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m2\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28mself\u001b[39m.layer2 = \u001b[43mC2f\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mself\u001b[39m.layer3 = Conv(\u001b[32m64\u001b[39m, \u001b[32m128\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m2\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;28mself\u001b[39m.layer4 = C2f(\u001b[32m128\u001b[39m, \u001b[32m128\u001b[39m, n=\u001b[32m2\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TUAN NGOC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:485\u001b[39m, in \u001b[36mModule.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    483\u001b[39m \u001b[38;5;66;03m# Backward compatibility: no args used to be allowed when call_super_init=False\u001b[39;00m\n\u001b[32m    484\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.call_super_init \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m485\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    486\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.__init__() got an unexpected keyword argument \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(kwargs))\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    487\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    488\u001b[39m     )\n\u001b[32m    490\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.call_super_init \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(args):\n\u001b[32m    491\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    492\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.__init__() takes 1 positional argument but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(args)\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m were\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    493\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m given\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    494\u001b[39m     )\n",
      "\u001b[31mTypeError\u001b[39m: C2f.__init__() got an unexpected keyword argument 'n'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    model = YOLOv8(num_classes=9)\n",
    "    dummy = torch.randn(1, 3, 640, 640) \n",
    "    outputs = model(dummy)\n",
    "    for i, out in enumerate(outputs):\n",
    "        print(f\"Scale P{i+3}: {out.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
